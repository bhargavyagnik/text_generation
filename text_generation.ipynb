{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOj51ge3ADN3/un5Xbw6+ne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "079d422d1a5d41c1bcf7ae6ad26af46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30aed73467764d7d8c7fdfc5c12bd1a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_237100d73d8049f2bf6994f4e47e58ce",
              "IPY_MODEL_f14bb6d0be7e4e3fa28e44e9d11a1da1"
            ]
          }
        },
        "30aed73467764d7d8c7fdfc5c12bd1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "237100d73d8049f2bf6994f4e47e58ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11708cafc85a42f481eb737515c0b41c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93b6c95af0d641228c68399a3d8eba3b"
          }
        },
        "f14bb6d0be7e4e3fa28e44e9d11a1da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2862332e5656413a95dfbc3b4d4db95c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.68MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ae9adde8ffa49fa9fe028488f940922"
          }
        },
        "11708cafc85a42f481eb737515c0b41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93b6c95af0d641228c68399a3d8eba3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2862332e5656413a95dfbc3b4d4db95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ae9adde8ffa49fa9fe028488f940922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30c8c66897544e51a1a87d9157ff59a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1dfaea3bbc644aa7bc4f992ac83e9daf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e70df0fd2d7b49c799255787a15d186e",
              "IPY_MODEL_78f9ff8067fd404fa5b362839fbc511d"
            ]
          }
        },
        "1dfaea3bbc644aa7bc4f992ac83e9daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e70df0fd2d7b49c799255787a15d186e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_452450fe999c421db3895e79feae9df5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2523f453b50f4e438a42c15d1184fd7b"
          }
        },
        "78f9ff8067fd404fa5b362839fbc511d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dbae43db3e6a4802821a1c1b93d961e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 2.90MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eaf69179b4404ba2a48f43a1b076e7c1"
          }
        },
        "452450fe999c421db3895e79feae9df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2523f453b50f4e438a42c15d1184fd7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbae43db3e6a4802821a1c1b93d961e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eaf69179b4404ba2a48f43a1b076e7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77241dfa46a74193978a412538916ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46cc42510a4f45d5bdb78a4d17393733",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7cd46c637be14d8297cb8bac57af6c67",
              "IPY_MODEL_4f1578def0a44832a527eba8a91ef666"
            ]
          }
        },
        "46cc42510a4f45d5bdb78a4d17393733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cd46c637be14d8297cb8bac57af6c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f1600d40b4342d2aed37b54eab162b8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_957a4a2d029c456f8333213989ca9ade"
          }
        },
        "4f1578def0a44832a527eba8a91ef666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9896349e267f4525a36b2045c7cf1232",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:10&lt;00:00, 61.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65d29d6fe4d04f0697a0d4c5b7304d34"
          }
        },
        "6f1600d40b4342d2aed37b54eab162b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "957a4a2d029c456f8333213989ca9ade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9896349e267f4525a36b2045c7cf1232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65d29d6fe4d04f0697a0d4c5b7304d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8739831bc6d54679b80370ab326a740a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4bafa1d576b34a6782abd8af7cbebd9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_37712a34a1dd437f95324dc0362c607f",
              "IPY_MODEL_4b6b6a6b4ff247aabab9e9ef5a141ea5"
            ]
          }
        },
        "4bafa1d576b34a6782abd8af7cbebd9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37712a34a1dd437f95324dc0362c607f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad676e69bef84b2b95df4c30c13ce921",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 497933648,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 497933648,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_272e248419784143a32909c1a729540d"
          }
        },
        "4b6b6a6b4ff247aabab9e9ef5a141ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8e01147ced74d6e9b208f6af4d07922",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 498M/498M [00:10&lt;00:00, 48.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b2279c9c7ab46dbb1e41b299ba3bdcc"
          }
        },
        "ad676e69bef84b2b95df4c30c13ce921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "272e248419784143a32909c1a729540d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8e01147ced74d6e9b208f6af4d07922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b2279c9c7ab46dbb1e41b299ba3bdcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhargavyagnik/text_generation/blob/main/text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9QrR5phhTSt"
      },
      "source": [
        "# Text Generation using Transformers library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAG7OH5qgqWH"
      },
      "source": [
        "This work is based on the Huggingface tutorial titled \"How to generate text: using different decoding methods for language generation with Transformers\" by  [Patrick Von Platen](https://huggingface.co/patrickvonplaten). \r\n",
        "\r\n",
        "I highly recommend you to check that ! It is quite detailed and very well explained.. The link to [Blog](https://huggingface.co/blog/how-to-generate) and the direct [Colab](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDGOp5fOhSgX"
      },
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\r\n",
        "!pip install -q tensorflow==2.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgS9vmQijeIE"
      },
      "source": [
        "!pip3 install --upgrade tensorflow-gpu # To overcome  the errors because of the versions "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "079d422d1a5d41c1bcf7ae6ad26af46c",
            "30aed73467764d7d8c7fdfc5c12bd1a4",
            "237100d73d8049f2bf6994f4e47e58ce",
            "f14bb6d0be7e4e3fa28e44e9d11a1da1",
            "11708cafc85a42f481eb737515c0b41c",
            "93b6c95af0d641228c68399a3d8eba3b",
            "2862332e5656413a95dfbc3b4d4db95c",
            "3ae9adde8ffa49fa9fe028488f940922",
            "30c8c66897544e51a1a87d9157ff59a4",
            "1dfaea3bbc644aa7bc4f992ac83e9daf",
            "e70df0fd2d7b49c799255787a15d186e",
            "78f9ff8067fd404fa5b362839fbc511d",
            "452450fe999c421db3895e79feae9df5",
            "2523f453b50f4e438a42c15d1184fd7b",
            "dbae43db3e6a4802821a1c1b93d961e9",
            "eaf69179b4404ba2a48f43a1b076e7c1",
            "77241dfa46a74193978a412538916ff4",
            "46cc42510a4f45d5bdb78a4d17393733",
            "7cd46c637be14d8297cb8bac57af6c67",
            "4f1578def0a44832a527eba8a91ef666",
            "6f1600d40b4342d2aed37b54eab162b8",
            "957a4a2d029c456f8333213989ca9ade",
            "9896349e267f4525a36b2045c7cf1232",
            "65d29d6fe4d04f0697a0d4c5b7304d34",
            "8739831bc6d54679b80370ab326a740a",
            "4bafa1d576b34a6782abd8af7cbebd9a",
            "37712a34a1dd437f95324dc0362c607f",
            "4b6b6a6b4ff247aabab9e9ef5a141ea5",
            "ad676e69bef84b2b95df4c30c13ce921",
            "272e248419784143a32909c1a729540d",
            "e8e01147ced74d6e9b208f6af4d07922",
            "4b2279c9c7ab46dbb1e41b299ba3bdcc"
          ]
        },
        "id": "fjaIPGqFhQ-t",
        "outputId": "71362436-4d3a-48ca-d040-f9494fab3a8d"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\r\n",
        "\r\n",
        "\r\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\r\n",
        "\r\n",
        "# add the EOS token as PAD token to avoid warnings\r\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "079d422d1a5d41c1bcf7ae6ad26af46c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30c8c66897544e51a1a87d9157ff59a4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77241dfa46a74193978a412538916ff4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8739831bc6d54679b80370ab326a740a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=497933648.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmw5PxBqkWDW"
      },
      "source": [
        "### **Greedy Search**\r\n",
        "\r\n",
        "Greedy search simply selects the word with the highest probability as its next word: $w_t = argmax_{w}P(w | w_{1:t-1})$ at each timestep $t$. The following sketch shows greedy search. \r\n",
        "\r\n",
        "![Greedy Search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/greedy_search.png)\r\n",
        "\r\n",
        "Starting from the word $\\text{\"The\"}$, the algorithm \r\n",
        "greedily chooses the next word of highest probability $\\text{\"nice\"}$ and so on, so that the final generated word sequence is $\\text{\"The\", \"nice\", \"woman\"}$ having an overall probability of $0.5 \\times 0.4 = 0.2$.\r\n",
        "\r\n",
        "In the following we will generate word sequences using GPT2 on the context $(\\text{\"I\", \"enjoy\", \"walking\", \"with\", \"my\", \"cute\", \"dog\"})$. Let's see how greedy search can be used in `transformers` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68lxrUOjikqa",
        "outputId": "dcefe4e5-347b-4c08-9c49-774730dae806"
      },
      "source": [
        "input_ids = tokenizer.encode('I am living in 2020',return_tensors='tf')\r\n",
        "greedy_output = model.generate(input_ids, max_length= 50)\r\n",
        "\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am living in 2020. I am not going to be able to afford to buy a car. I am not going to be able to afford to buy a house. I am not going to be able to afford to buy a house. I am\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX_D7TUXnpfy",
        "outputId": "054f10db-85ad-4886-8d8b-89cf67df7776"
      },
      "source": [
        "greedy_output"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 50), dtype=int32, numpy=\n",
              "array([[   40,   716,  2877,   287, 12131,    13,   314,   716,   407,\n",
              "         1016,   284,   307,  1498,   284,  5368,   284,  2822,   257,\n",
              "         1097,    13,   314,   716,   407,  1016,   284,   307,  1498,\n",
              "          284,  5368,   284,  2822,   257,  2156,    13,   314,   716,\n",
              "          407,  1016,   284,   307,  1498,   284,  5368,   284,  2822,\n",
              "          257,  2156,    13,   314,   716]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5zAHg3ynmaL"
      },
      "source": [
        "Alright! We have generated our first short text with GPT2 ðŸ˜Š. The generated words following the context are reasonable, but the model quickly starts repeating itself! This is a very common problem in language generation in general and seems to be even more so in greedy and beam search - check out [Vijayakumar et al., 2016](https://arxiv.org/abs/1610.02424) and [Shao et al., 2017](https://arxiv.org/abs/1701.03185).\r\n",
        "\r\n",
        "The major drawback of greedy search though is that it misses high probability words hidden behind a low probability word as can be seen in our sketch above:\r\n",
        "\r\n",
        "The word $\\text{\"has\"}$ with its high conditional probability of $0.9$ is hidden behind the word $\\text{\"dog\"}$, which has only the second-highest conditional probability, so that greedy search misses the word sequence $\\text{\"The\"}, \\text{\"dog\"}, \\text{\"has\"}$.\r\n",
        "\r\n",
        "Thankfully, we have beam search to alleviate this problem!\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRLzFRC-oGKX"
      },
      "source": [
        "### **Beam search**\r\n",
        "\r\n",
        "Beam search reduces the risk of missing hidden high probability word sequences by keeping the most likely `num_beams` of hypotheses at each time step and eventually choosing the hypothesis that has the overall highest probability. Let's illustrate with `num_beams=2`:\r\n",
        "\r\n",
        "![Beam search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/beam_search.png)\r\n",
        "\r\n",
        "At time step $1$, besides the most likely hypothesis $\\text{\"The\", \"woman\"}$, beam search also keeps track of the second most likely one $\\text{\"The\", \"dog\"}$. At time step $2$, beam search finds that the word sequence $\\text{\"The\", \"dog\", \"has\"}$ has with $0.36$ a higher probability than $\\text{\"The\", \"nice\", \"woman\"}$, which has $0.2$. Great, it has found the most likely word sequence in our toy example! \r\n",
        "\r\n",
        "Beam search will always find an output sequence with higher probability than greedy search, but is not guaranteed to find the most likely output. \r\n",
        "\r\n",
        "Let's see how beam search can be used in `transformers`. We set `num_beams > 1` and `early_stopping=True` so that generation is finished when all beam hypotheses reached the EOS token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCzqlKfolF5R",
        "outputId": "201f0b0e-8adc-4b41-a470-676b7d7448e8"
      },
      "source": [
        "# activate beam search and early_stopping\r\n",
        "beam_output = model.generate(\r\n",
        "    input_ids,  \r\n",
        "    max_length=50, \r\n",
        "    num_beams=5, \r\n",
        "    early_stopping=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am living in 2020.\"\n",
            "\n",
            "\"I am living in 2020.\"\n",
            "\n",
            "\"I am living in 2020.\"\n",
            "\n",
            "\"I am living in 2020.\"\n",
            "\n",
            "\"I am living in 2020.\"\n",
            "\n",
            "\"I am living in 2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_DZHTW7nvTX",
        "outputId": "c44da919-5718-4a27-9735-3447a1d1c474"
      },
      "source": [
        "import time\r\n",
        "# activate beam search and early_stopping\r\n",
        "n , m = 3,7\r\n",
        "t=  time.time()\r\n",
        "beam_output = model.generate(\r\n",
        "    input_ids,  \r\n",
        "    max_length=50, \r\n",
        "    num_beams=n, \r\n",
        "    early_stopping=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))\r\n",
        "print(\"Time to run with \",n,\" Beams \",time.time()-t)\r\n",
        "\r\n",
        "t=time.time()\r\n",
        "beam_output = model.generate(\r\n",
        "    input_ids,  \r\n",
        "    max_length=50, \r\n",
        "    num_beams=m, \r\n",
        "    early_stopping=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))\r\n",
        "print(\"Time to run with \",m,\" Beams \",time.time()-t)\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am living in 2020, and I am not going to be able to afford to live in the future,\" he said.\n",
            "\n",
            "\"I am not going to be able to afford to live in the future. I am not going to be able\n",
            "Time to run with  3  Beams  25.00346040725708\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am living in 2020,\" he said.\n",
            "\n",
            "\"I am living in 2020. I am living in 2020. I am living in 2020. I am living in 2020. I am living in 2020. I am living in 2020. I am\n",
            "Time to run with  7  Beams  27.91623091697693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhgsX3Y2p2QW"
      },
      "source": [
        "While the result is arguably more fluent, the output still includes repetitions of the same word sequences.  \r\n",
        "A simple remedy is to introduce *n-grams* (*a.k.a* word sequences of $n$ words) penalties as introduced by [Paulus et al. (2017)](https://arxiv.org/abs/1705.04304) and [Klein et al. (2017)](https://arxiv.org/abs/1701.02810). The most common *n-grams* penalty makes sure that no *n-gram* appears twice by manually setting the probability of next words that could create an already seen *n-gram* to $0$.\r\n",
        "\r\n",
        "Let's try it out by setting `no_repeat_ngram_size=2` so that no *2-gram* appears twice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQOhu-rmphnY",
        "outputId": "6cd928c6-495f-4895-81f9-7ae689e66e39"
      },
      "source": [
        "# set no_repeat_ngram_size to 2\r\n",
        "beam_output = model.generate(\r\n",
        "    input_ids, \r\n",
        "    max_length=50, \r\n",
        "    num_beams=5, \r\n",
        "    no_repeat_ngram_size=2, \r\n",
        "    early_stopping=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am living in 2020, and I am not going to be able to afford to live in the future,\" he said.\n",
            "\n",
            "\"I don't know if I can afford it, but it's not a problem for me. It's a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oiji_6msqn7l"
      },
      "source": [
        "Nice, that looks much better! We can see that the repetition does not appear anymore. Nevertheless, *n-gram* penalties have to be used with care. An article generated about the city *New York* should not use a *2-gram* penalty or otherwise, the name of the city would only appear once in the whole text!\r\n",
        "\r\n",
        "Another important feature about beam search is that we can compare the top beams after generation and choose the generated beam that fits our purpose best. \r\n",
        "\r\n",
        "In `transformers`, we simply set the parameter `num_return_sequences` to the number of highest scoring beams that should be returned. Make sure though that `num_return_sequences <= num_beams`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xZpyLeIqK4C",
        "outputId": "f7e60afd-b7af-4fd0-9ff8-584e7287d8a2"
      },
      "source": [
        "# set return_num_sequences > 1\r\n",
        "beam_outputs = model.generate(\r\n",
        "    input_ids, \r\n",
        "    max_length=50, \r\n",
        "    num_beams=5, \r\n",
        "    no_repeat_ngram_size=2, \r\n",
        "    num_return_sequences=5, \r\n",
        "    early_stopping=True\r\n",
        ")\r\n",
        "\r\n",
        "# now we have 3 output sequences\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "for i, beam_output in enumerate(beam_outputs):\r\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I am living in 2020, and I am not going to be able to afford to live in the future,\" he said.\n",
            "\n",
            "\"I don't know if I can afford it, but it's not a problem for me. It's a\n",
            "1: I am living in 2020, and I am not going to be able to afford to live in the future,\" he said.\n",
            "\n",
            "\"I don't know if I can afford it, but it's not a problem for me. I'm not\n",
            "2: I am living in 2020, and I am not going to be able to afford to live in the future,\" he said.\n",
            "\n",
            "\"I don't know if I can afford it, but it's not a problem for me. It's just\n",
            "3: I am living in 2020, and I am not going to be able to afford to live in the future,\" he said.\n",
            "\n",
            "\"I don't know if I can afford it, but it's not a problem for me. I'm going\n",
            "4: I am living in 2020, and I am not going to be able to afford to live in the future,\" he said.\n",
            "\n",
            "\"I don't know if I can afford it, but it's not a problem for me. I have a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "velF8_gHq5xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e375f2-d6f5-4f93-e93b-2040ea08792b"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# set no_repeat_ngram_size to 2\r\n",
        "beam_output = model.generate(\r\n",
        "    input_ids, \r\n",
        "    max_length=1000, \r\n",
        "    num_beams=5, \r\n",
        "    no_repeat_ngram_size=2, \r\n",
        "    early_stopping=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "That night i was speaking with the books, All about my average looks.\n",
            "\n",
            "The next day i went to the store and bought a few books. The first book i bought was a book called \"How to Be a Man\". The second book was about how to be a man. I bought the third book and the fourth book. Then the fifth book came out and i had to buy the sixth book because i didn't have the money to pay for it. So i decided to go back to my old life and buy a new one.\n",
            "\n",
            "\n",
            "When i got home i found out that my wife had died. She had been in a coma for a year and a half. My wife was in the hospital for two weeks and she had a lot of pain in her body. It was so bad that she couldn't walk. When i came home she told me that her husband had taken her to a doctor and that he had told her he was going to give her a heart transplant. He said he would give it to her if she gave him the heart, but she said she would have to wait until she was old enough to get the transplant, so she went with him to see the doctor. After a while he said that it was too late for her, and he wanted to make sure she got the transplanted heart. That's when i started to think about what would happen if i did not give my heart to someone who was dying of heart failure. And then i realized that i could do anything i wanted with my life, even if it took me a long time to do so. In the end i gave up on my dream of getting a transplant and started living a normal life.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tuaRAKmK34p"
      },
      "source": [
        "As can be seen, the five beam hypotheses are only marginally different to each other - which should not be too surprising when using only 5 beams.\r\n",
        "\r\n",
        "In open-ended generation, a couple of reasons have recently been brought forward why beam search might not be the best possible option:\r\n",
        "\r\n",
        "- Beam search can work very well in tasks where the length of the desired generation is more or less predictable as in machine translation or summarization - see [Murray et al. (2018)](https://arxiv.org/abs/1808.10006) and [Yang et al. (2018)](https://arxiv.org/abs/1808.09582). But this is not the case for open-ended generation where the desired output length can vary greatly, e.g. dialog and story generation.\r\n",
        "\r\n",
        "- We have seen that beam search heavily suffers from repetitive generation. This is especially hard to control with *n-gram*- or other penalties in story generation since finding a good trade-off between forced \"no-repetition\" and repeating cycles of identical *n-grams* requires a lot of finetuning.\r\n",
        "\r\n",
        "- As argued in [Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751), high quality human language does not follow a distribution of high probability next words. In other words, as humans, we want generated text to surprise us and not to be boring/predictable. The authors show this nicely by plotting the probability, a model would give to human text vs. what beam search does.\r\n",
        "\r\n",
        "![alt text](https://blog.fastforwardlabs.com/images/2019/05/Screen_Shot_2019_05_08_at_3_06_36_PM-1557342561886.png)\r\n",
        "\r\n",
        "\r\n",
        "So let's stop being boring and introduce some randomness ðŸ¤ª."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDu4k9R9K7bH"
      },
      "source": [
        "### **Sampling**\r\n",
        "\r\n",
        "In its most basic form, sampling means randomly picking the next word $w_t$ according to its conditional probability distribution:\r\n",
        "\r\n",
        "$$w_t \\sim P(w|w_{1:t-1})$$\r\n",
        "\r\n",
        "Taking the example from above, the following graphic visualizes language generation when sampling.\r\n",
        "\r\n",
        "![vanilla_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/sampling_search.png)\r\n",
        "\r\n",
        "It becomes obvious that language generation using sampling is not *deterministic* anymore. The word \r\n",
        "$\\text{\"car\"}$ is sampled from the conditioned probability distribution $P(w | \\text{\"The\"})$, followed by sampling $\\text{\"drives\"}$ from $P(w | \\text{\"The\"}, \\text{\"car\"})$.\r\n",
        "\r\n",
        "In `transformers`, we set `do_sample=True` and deactivate *Top-K* sampling (more on this later) via `top_k=0`. In the following, we will fix `random_seed=0` for illustration purposes. Feel free to change the `random_seed` to play around with the model.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12XvlWDcsC5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a970ec8-a0c3-47c8-a86b-bbcb79f4628b"
      },
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\r\n",
        "tf.random.set_seed(0)\r\n",
        "\r\n",
        "# activate sampling and deactivate top_k by setting top_k sampling to 0\r\n",
        "sample_output = model.generate(\r\n",
        "    input_ids, \r\n",
        "    do_sample=True, \r\n",
        "    max_length=50, \r\n",
        "    top_k=0\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am living in 2020. It's been a long time but I love having you to help me along the way on my journey. We just flew from California to Arizona and flew back to Chicago in early September.\n",
            "\n",
            "I would like to keep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNqQ6RhNN9l2"
      },
      "source": [
        "Interesting! The text seems alright - but when taking a closer look, it is not very coherent. the *3-grams* *new hand sense* and *local batte harness* are very weird and don't sound like they were written by a human. That is the big problem when sampling word sequences: The models often generate incoherent gibberish, *cf.* [Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751).\r\n",
        "\r\n",
        "A trick is to make the distribution $P(w|w_{1:t-1})$ sharper (increasing the likelihood of high probability words and decreasing the likelihood of low probability words) by lowering the so-called `temperature` of the [softmax](https://en.wikipedia.org/wiki/Softmax_function#Smooth_arg_max). \r\n",
        "\r\n",
        "An illustration of applying temperature to our example from above could look as follows.\r\n",
        "\r\n",
        "![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/sampling_search_with_temp.png?raw=true)\r\n",
        "\r\n",
        "The conditional next word distribution of step $t=1$ becomes much sharper leaving almost no chance for word $\\text{\"car\"}$ to be selected.\r\n",
        "\r\n",
        "\r\n",
        "Let's see how we can cool down the distribution in the library by setting `temperature=0.7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwAuExy2K94E",
        "outputId": "457efee0-41dd-4faf-ffef-8d1ca72f8425"
      },
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\r\n",
        "tf.random.set_seed(0)\r\n",
        "\r\n",
        "# use temperature to decrease the sensitivity to low probability candidates\r\n",
        "sample_output = model.generate(\r\n",
        "    input_ids, \r\n",
        "    do_sample=True, \r\n",
        "    max_length=50, \r\n",
        "    top_k=0, \r\n",
        "    temperature=0.7\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Output:\\n\" + 100 * '-')\r\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am living in 2020. I am not a tax money tranny who takes all the money and keeps it. I am not a tax money money tranny who takes all the money and keeps it.\n",
            "\n",
            "\"I would like to have a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QaN7vU9OAZL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}